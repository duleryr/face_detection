\documentclass[a4paper,11pt]{article}
\pagestyle{headings}

\usepackage[utf8]{inputenc}
\usepackage{diagbox}
\usepackage[french]{babel}
\usepackage{graphicx}
\usepackage{float}
\usepackage{fullpage}
\usepackage{hyperref}
\usepackage{diagbox}
\usepackage{enumitem}
\usepackage[T1]{fontenc}
\usepackage[]{algorithm2e}
\graphicspath{{images/}}

\title{Reconnaissance de formes et apprentissage automatique Projet 3}
\author{Auriane Reverdell, Felix Hähnlein, Nicolas Violette, Romain Duléry}
\date{\today}

\setlength{\oddsidemargin}{0.2cm}
\setlength{\evensidemargin}{-0.7cm}
\setlength{\parindent}{30pt}
\setlength{\textwidth}{15cm}
\setlength{\textheight}{24cm}
\setlength{\topmargin}{-.5in}
\setlength{\parskip}{1ex}


\begin{document}

\maketitle
\vspace{1cm}

\section{Problématique et objectifs}

\section{Utilisation de notre propre réseau de neurones}
\subsection{Architecture utilisée}
\subsection{Entraînement et choix de paramètres}
- taux d'apprentissage: adaptative
- si cost décroit, mais la précision n'augmente plus, ça veut dire que la capacité du réseau à capter le problème est saturée => augmenter la complexité du modèle
- la fonction loss: l'entropie croisée n'augmente pas forcément l'accuracy
\subsection{Evaluation des résultats}
\subsubsection{Evaluation par courbes ROC et Precision-Recall}
\subsubsection{Visualisation des filtres obtenus}

\section{Apprentissage par transfert : Réseaux de neurones préentraînés}
\subsection{Présentation de la méthode utilisée}

L'idée de l'apprentissage par transfert (\textit{fine-tuning}) est une spécialisation de l'apprentissage dans un domaine particulier. Il s'agit de se fonder sur un réseau préentraîné sur une grande base de données, en continuant de l'entraîner dans le domaine qui nous intéresse, ici la reconnaissance faciale.

Etant donné que les bases de données originales sont énormes, le modèle pré-entraîné aura déjà appris des features pertinentes pour notre problème.

Par ailleurs, l'apprentissage par transfert est applicable à notre problème car il n'est pas trop spécifique, sinon les modèles pré-entraînés seraient inaptes à nous aider.

Etant donné que notre base de données de test est relativement petite, l'apprentissage par transfert pourrait amener au surapprentissage (\textit{overfitting}), on utilise donc des stratégies de complétion des données d'entrée, comme présenté dans la partie \ref{sec:completion}.

\subsection{Entraînement}
\subsection{Evaluation des résultats}

\section{Complétion de la base de données d'entrée}
\label{sec:completion}

https://fr.wikipedia.org/wiki/Surapprentissage \\
https://en.wikipedia.org/wiki/Overfitting

\subsection{Nécessité de compléter la base de données}
\subsection{Méthodes de complétion}
    \subsection{Notes Auriane}
    Dans quelle mesure faut il appliquer les transformations sur toutes les images de la base ?
    (l'application sur 1/4 de la base ne suffirait-elle pas ?)

\section{Annexes}
\section{Bibliographie}
http://ydwen.github.io/papers/WenECCV16.pdf

\end{document}
